\documentclass[11pt]{article}

\usepackage{fullpage} % Package to use full page
\usepackage{parskip} % Package to tweak paragraph skipping
\usepackage{tikz} % Package for drawing
\usepackage{amsmath}
\usepackage[breaklinks]{hyperref}
\usepackage{url}
\usepackage{breakurl} 
\usepackage{enumerate}
\usepackage{subcaption}
\usepackage{mathptmx}
\usepackage{epsfig}
\usepackage{multirow}
\usepackage{wrapfig}
%\usepackage{minipage}
\def \hfillx {\hspace*{-\textwidth} \hfill}

\title{Evading the Machine Learning Detector: A Virusâ€™ Perspective}
\author{Group 10 \\ Yuan Xiao, Xiaokuan Zhang}
\date{04/27/2017}



\begin{document}

\maketitle
\section*{Abstract}
In this project, we intend to explore the classification-based virus scanners from the perspective of virus. We developed effective anti-antivirus schemes against a known classification model as the scanner. By adding or removing key attributes from the malicious executable instances, we are able to fool the scanner into classifying a malicious instance as a non-malicious one. We did exploration about how to choose the attributes to be modified and designed our self-defined Relative-Ratio-based feature selection. We also compared our method with the feature selection methods from Weka and LibSVM.


\section{Introduction}

\subsection{Problem Description}
There are a bunch of anti-virus software on market nowadays, such as Norton and McAfee. They can detect malicious apps/binaries and prevent them from jeopardizing the user's data. However, in our project, we are not aiming at improving the detection rate of anti-virus software; instead, we want to study from a virus' perspective: how should a virus disguise itself to evade the detection? To answer this question, we designed a novel evasion scheme and conducted experiments the test its efficiency on a dataset from UCI Machine Learning Repository. We will introduce them in more detail in Section \ref{sec:exp}.

\subsection{Classification Algorithms}
In this project, we use LibSVM \cite{CC01a} as our machine learning  algorithm, which implements Support Vector Machine (SVM). To compare with our feature selection scheme, we use Weka's \texttt{weka.attributeSelection.CfsSubsetEval} module as the feature selection method. It implements correlation-based feature selection. We will present the detail of algorithms in Section \ref{sec:metho}.

\subsection{Assumptions} \label{sec:assumption}
We make reasonable assumptions in this project. The classifier should be already known to the attacker and will not change after it is trained. Thus, in experiments we assume that the training set and classification algorithm are both known and the classification model can be trained by the attacker. After the attacker does change to the malicious executables, the classification model remains and will not be re-trained using the modified data.

\subsection{Originality}

\subsection{Result Summary}
Our results show that our scheme works well and can truly fool the detector.
% For the hand-written digit dataset, after tuning the parameters, the three classifiers can achieve 98.97\%, 93.27\%, 92.02\%  accuracy. For the letter dataset, they can reach 95.33\%, 82.77\%, 74.18\% accuracy. We only submit a \texttt{pdf} file and a \texttt{tex} file to Carmen. For a more detailed view of our repository, please visit our repo on github \footnote{https://github.com/XiaokuanOSU/AI2report}.

\section{Background}
The author of the dataset we used generated the dataset based on the n-gram feature set construction from Masud et al.'s paper \cite{masud2007hybrid}. In this paper, they proposed a new way to construct features for binary files, called N-gram Features. An n-gram may be either a sequence of n bytes or n assembly instructions, or n DLL function calls, depending on whether they want to extract features from binary or assembly program, or DLL call list. For example, the 3-grams corresponding to the 4 bytes sequence "a1b2c3d4" are "a1b2c3" and "b2c3d4". They constructed Binary/Assembly/DLL N-gram feature set, and proposed a hybrid model to combine the three feature sets. Then, they choose best 500 features for each set based on entropy gain. Later on, they use LibSVM to test their models. The hybrid model works best for both datasets (Accuracy:96.30\%, 96.15\%).

There is an older paper about detecting malicious executables by Schultz et al. \cite{schultz2001data}. In their paper, they constructed DLLs, GNU Strings, and Byte Sequence features. The DLL and Byte Sequence features are similar to the way of constructing our dataset, but they did not use N-gram feature. They further tested their features using different machine learning algorithms, i.e., RIPPER, Naive Bayes, and Multi-Naive Bayes. The best one (Multi-Naive Bayes) can achieve 97.76\% detection rate.


% \begin{figure}[htbp]
% \centering

% \begin{subfigure}[htbp]{0.32\columnwidth}
% \includegraphics*[width=\textwidth]{fig/ex_digit}
% \caption{A Digit Example: 2}
% \label{fig:ex:digit}
% \end{subfigure}
% \hfill
% \begin{subfigure}[htbp]{0.32\columnwidth}
% \includegraphics*[width=\textwidth]{fig/ex_letter}
% \caption{Letter Examples}
% \label{fig:ex:letter}
% \end{subfigure}
% \hfill
% \begin{subfigure}[htbp]{0.32\columnwidth}
% \includegraphics*[width=\textwidth]{fig/feature_letter}
% \caption{Features of Letters}
% \label{fig:feature:letter}
% \end{subfigure}
% \caption{Examples and Features}
% \end{figure}

\section{Methodology}\label{sec:metho}

\subsection{Tools}
\subsubsection{LibSVM}
LibSVM \cite{CC01a} is an open-source software that implements Support Vector Machine (SVM) algorithm \cite{cortes1995support}. It is one of the most popular tools when it comes to SVM implementation. It is the main tool that we use to test the performance our evasion scheme. 

\subsubsection{Weka}
Weka \cite{hall2009weka} is a collection of machine learning algorithms for data mining tasks. It has a nice GUI interface and can accept different file inputs (e.g, .arff, .csv, etc.). In our project, our main task is to find important features to add or delete (feature selection). Therefore, we use Weka as a tool for feature selection and compare the performance with our feature selection scheme.

\subsection{Algorithms}
\subsubsection{SVM}
SVM \cite{cortes1995support} is a supervised learning model that analyzes data for classification or regression. Provided with a set of training examples, which are marked with their belonging categories, a SVM algorithm performs to build a model so as to recognize and assign testing examples to the predicted categories. 

\subsubsection{Correlation-based Feature Selection}
We choose the \texttt{weka.attributeSelection.CfsSubsetEval} module as the feature selection method to compare with our scheme. It implements correlation-based feature selection, which evaluates the worth of a subset of attributes by considering the individual predictive ability of each feature along with the degree of redundancy between them \cite{hall1999correlation}.

\subsubsection{Relative Ratio Feature Selection}
In this project, we came up with a novel way to select features to modify, which is specific to this project only. We will propose our method in detail in Section \ref{sec:exp}.

\section{Experiments}\label{sec:exp}
% The whole experiment is made up of four steps. First, data preprocessing. Second, model training with LibSVM and testing with unmodified test set. Thus we have a criterion for evaluation. Third, data modification in the test set and testing using trained libSVM model. Fourth, performance comparison. The methods for model training and data modification are already described in section \ref{sec:metho} and the rest parts will be discussed in the this section.


\subsection{Original Dataset}
The dataset includes instances of malicious executables (computer virus) as well as non-malicious executables (normal programs). The features are extracted from real-world malicious and non-malicious executables. The dataset was published in March 2016 in UCI Machine Learning Repository. Within one year, the web hits of the dataset has already reached over 200,000. It is obvious that the dataset arouses great interest in the machine learning community.

The dataset consists of 373 instances, of which 301 are malicious and 72 are benign. Each instance has 500 hex features and 30 DLL features. Examples of hex features and DLL features are shown in Fig. \ref{fig:hexDLL}. Notice that on the UCI webpage it claims that there are 13 DLL features but we found from the raw data that there are actually 30 of them. All the attributes are binary, meaning a certain feature exists or not. 

However, the primary weakness of the dataset is that the sample number is relatively low. However, the goal of our project is not to exhaustively find the best machine learning model to classify malicious and non-malicious executables. Thus we think the low sample amount is tolerable. In addition, after searching online, the UCI dataset is the only dataset available that do not require extracting features by ourselves.



\begin{figure}[htbp]
\centering
\begin{subfigure}[htbp]{0.4\columnwidth}
\includegraphics*[width=\textwidth]{fig/hex}
\caption{Hex Feature}
\label{fig:hex}
\end{subfigure}
\hfill
\begin{subfigure}[htbp]{0.57\columnwidth}
\includegraphics*[width=\textwidth]{fig/DLL}
\caption{DLL Feature}
\label{fig:DLL}
\end{subfigure}
\label{fig:hexDLL}
\end{figure}

% \hfill
% \begin{subfigure}[htbp]{0.46\columnwidth}
% \includegraphics*[width=\textwidth]{fig/smo_libsvm}
% \caption{Comparison between SMO and LibSVM}
% \label{fig:smo-libsvm}
% \end{subfigure}
% \caption{Performance of Support Vector Machine}
% \label{fig:svm}
% \end{figure}


% \begin{figure}[htbp]
% \centering

% \begin{subfigure}[htbp]{0.46\columnwidth}
% \includegraphics*[width=\textwidth]{fig/digit_ANN}
% \caption{Digit Classification}
% \label{fig:digit-ann}
% \end{subfigure}
% \hfill
% \begin{subfigure}[htbp]{0.46\columnwidth}
% \includegraphics*[width=\textwidth]{fig/digit_ANN_special}
% \caption{L=0.6 in Digit Classification}
% \label{fig:digit-ann-special}
% \end{subfigure}
% \hfill
% \begin{subfigure}[htbp]{0.46\columnwidth}
% \includegraphics*[width=\textwidth]{fig/letter_ANN}
% \caption{Letter Recognition}
% \label{fig:letter-ann}
% \end{subfigure}
% \caption{Performance of Multilayer Perceptron}
% \label{fig:ann}
% \end{figure}


\subsection{Work Flow}
The whole experiment is made up of four steps. %First, data preprocessing. Second, model training with LibSVM and testing with unmodified test set. Thus we have a criterion for evaluation. Third, data modification in the test set and testing using trained libSVM model. We need to determine which features we want to add or delete for malicious samples, which is the key of our experiment. Fourth, performance comparison. 
We will go through each step in detail.

\subsubsection{Data Preprocessing}
The raw data is generally LibSVM-format conformant. The class attribute at the beginning of an instance marks whether it is benign or malicious. -1 stands for a malicious instance and +1 means benign. However, at the end of each instance there is an additional -1. We need to remove it before passing it to LibSVM as input.

\subsubsection{Model Training \& Testing}
After data preprocessing, we pass the training set to LibSVM to train a classification model. In \ref{sec:assumption}, we mentioned that the model is known to the attacker, and it will not change when the test set changes. %With the different cores, we will have different models. The following implementations apply to all of the models.

Given a trained classification model, we apply it to the test set first and get the test results as a criterion for later evaluation. With the unmodified test set, we expect the performance of the model to classify malicious instances to be high enough. Otherwise, the model itself does not make sense and it is pointless to fool an inaccurate classification model.


\subsubsection{Attribute Modification}
Now that we have a model, we can apply different attribute modification methods to the test set. Notice that only malicious instances are modified since our only goal is to disguise a malicious executable as a benign one. More specifically, we use different feature selection methods to find the right attributes to modify (add or delete attributes). With different modified test sets, we re-do the testing phase with unmodified classification model. 

\subsubsection{Performance Evaluation}
In the end, we compare the new test result with the original one and see whether the detection rate drops. Moreover, we compare the escape results of different modification methods to find which one performs best. 

\subsection{Relative Ratio Feature Selection}
At first, we chose to modify only one attribute. We modified each of the 530 attribute (add or delete), but none of them affected the performance of the original model. We cannot simply choose any two of them, because there are too many combinations. To solve this problem, we came up with a novel way to perform the feature selection, and we call it Relative Ratio feature selection. In this part, we will introduce this method in detail.

For every attribute X (1~530) in the training set, first, we compute the \texttt{Positive Ratio (PR)} using the following equation:

\begin{equation}
PR(X) = \frac{\text{benign instances that have attribute X}}{\text{total benign instances}}
\end{equation}

Similarly, we also compute the Nagative Ratio (NR) using the following equation:

\begin{equation}
NR(X) = \frac{\text{malicious instances that have attribute X}}{\text{total malicious instances}}
\end{equation}

Then, the \texttt{Relative Ratio (RR)} is defined as follows:

\begin{equation}
RR(X) = PR(X) - NR(X)
\end{equation}

Here, if an attribute X has high \texttt{RR}, it means that attribute X appears more often in benign samples; On the other hand, if an attribute X has low \texttt{RR}, it means that attribute X appears more often in malicious samples.

After calculating \texttt{RR} for all 530 attributes, we sort them in descending order and obtain an attribute list, \texttt{RRList}. In \texttt{RRList}, if attribute X appears earlier than Y, it means that X has larger \texttt{RR} values than Y. Then, we can perform two kinds of modification strategies:
\begin{enumerate}
\item {Adding attributes.} 
We can add top N attributes in \texttt{RRList} to the malicious samples. By adding N attributes that have high \texttt{RRs}, we make the viruses become more like benign samples.
\item {Removing attributes.}
We can remove last N attributes in \texttt{RRList} to the malicious samples, should they have such attributes. By removing N attributes that have low \texttt{RRs}, we make the viruses become less like malicious samples.
\end{enumerate}

% \begin{wraptable}[13]{r}{0.5\textwidth}
% \centering
% \begin{tabular}{c  c  c} \hline
% % centering table
% % creating 10 columns
% % inserting double-line 

% Parameters & Class (Letter) & Accuracy \\\hline
% \multirow{3}{*}{K = linear, C = 1} & S & 68\% \\
% 	& H & 69.8\% \\
% 	& R & 73.8\% \\\hline
% \multirow{3}{*}{K = poly, C = 1} & H & 91\% \\
% 	& R & 91\% \\
% 	& S & 64\% \\\hline
% \multirow{3}{*}{K = linear, C = 2} & S & 67.5\% \\
% 	& H & 69.7\% \\
% 	& B & 92.4\% \\\hline
% \multirow{3}{*}{K = poly, C = 2} & R & 90.8\% \\
% 	& H & 91.1\% \\
% 	& F & 92.5\% \\\hline
% \end{tabular}
% \caption{Worst Cases: Support Vector Machine} % title name of the table
% \label{tbl:svm}
% \end{wraptable}
%\vspace{10cm}

\subsection{Relative Ratio Evaluation}
\subsubsection{Adding Attributes}
The first strategy we tried was to add the top N attributes according to their RR. We tried different N numbers and evaluated how they performed with precision and recall. As shown in figure xx and figure yy, there is an obvious performance drop when N reaches about 35?. When less than 25? attributes are added, the classifier stays robust to the changes and the malicious instances are not able to escape the detection. However, take N=35? as a threshold, when more than threshold attributes are added, almost all the malicious instances successfully fool the classifier to think they are benign.

Precision: Recall: 

\subsubsection{Removing Attributes}
Similar to adding attributes, we did experiments on removing them as well. We tried different N numbers and evaluated how they performed with precision and recall. The evaluation result is also close to adding them. When removing less than threshold number of attributes, none of the malicious instances are mis-classified. But when the number of removed attributes increases to over threshold, all of them succeeds in escaping the detection.

If we do further comparison between adding and removing attributes, as shown in figure zz, the threshold of removing attributes turns out to be lower than that of adding attributes. This suggests that removing attributes is easier to fool the classification-based virus detector than adding attributes.

\subsection{Comparison with Correlation-based Feature Selection}
In order to compare our RR-based feature selection with correlation-based feature selection, we specified the same number of attributes to be added and applied the different feature selection methods. Then we record and compare the performance of the classifier towards the different modified test set. Judging from figure xx, we are able to see that ...

\section{Discussion}

\subsection{Real-world Feasibility}
In this section we briefly discusses the feasibility of our modification towards the malicious executables and compare them with existing anti-antivirus methods deployed by real-world virus.

In reality, it is much more difficult to remove features than to add features. The features to remove mostly denote the malicious behavior of a virus and are thus hard to take out. In contrast, we can easily add features as dummy code that will never be executed.

Our modification schemes in fact serves as a combination of two existing anti-antivirus methods. The first is to disguise as popular file formats such as .pdf or .docx or programs such as calc.exe or notepad.exe. The second is polymorphic virus. It mutates on each copy by adding different types of NOP instructions.

\subsection{Defense Mechanisms}

\section{Conclusion}
By modifying the top N attributes according to our self-defined RR or correlation-based feature selection mechanisms, we are able to fool the given SVM model into mistakenly classifying a malicious executable as a non-malicious one. Removing attributes works better than adding them, but in practice the difficulty of adding features is lower than that of removing. In real world scenario, our hiding scheme serves as the combination of two existing schemes. Thus it is feasible in real world under the given assumptions.


% \begin{figure}[htbp]
% \centering

% \begin{subfigure}[htbp]{0.46\columnwidth}
% \includegraphics*[width=\textwidth]{fig/digit_bayes}
% \caption{Digit Classification}
% \label{fig:digit-bayes}
% \end{subfigure}
% \hfill
% \begin{subfigure}[htbp]{0.46\columnwidth}
% \includegraphics*[width=\textwidth]{fig/letter_bayes}
% \caption{Letter Recognition}
% \label{fig:letter-bayes}
% \end{subfigure}
% \caption{Performance of Naive Bayes}
% \label{fig:bayes}
% \end{figure}

 
%  \begin{table}[!htb]
% %\begin{subtable}

% \centering
% \begin{minipage}{0.46\columnwidth}
% \begin{tabular}{c  c  c} \hline
% % centering table
% % creating 10 columns
% % inserting double-line 

% Parameters & Class (Letters) & Accuracy \\\hline
% \multirow{3}{*}{Default} & G & 69\% \\
% 	& H & 64.4\% \\
% 	& S & 65\% \\\hline
% \multirow{3}{*}{L = 0.6} & G & 68.2\% \\
% 	& H & 69.1\% \\
% 	& S & 64\% \\\hline
% \multirow{3}{*}{N = 200} & G & 69.3\% \\
% 	& H & 65.1\% \\
% 	& S & 64.4\% \\\hline
% \end{tabular}
% \caption{Worst Cases: Multilayer Perceptron} % title name of the table
% \label{tbl:ann}
% \end{minipage}
% \hfill
% \begin{minipage}{0.46\columnwidth}
% \begin{tabular}{c  c  c} \hline
% % centering table
% % creating 10 columns
% % inserting double-line 

% Parameters & Class (Letters) & Accuracy \\\hline
% \multirow{3}{*}{K = F, D = F} & S & 29.4\% \\
% 	& H & 30.5\% \\
% 	& Y & 33.1\% \\\hline
% \multirow{3}{*}{K = T, D = F} & H & 57.4\% \\
% 	& S & 64.2\% \\
% 	& X & 64.3\% \\\hline
% \multirow{3}{*}{K = F, D = T} & H & 57.5\% \\
% 	& E & 60.7\% \\
% 	& X & 64.4\% \\\hline
% \end{tabular}
% \caption{Worst Cases: Naive Bayes} % title name of the table
% \label{tbl:bayes}
% \end{minipage}
% %\end{subtable} 
% \end{table}


\newpage
\bibliographystyle{plain}
\bibliography{Group10}
\end{document}







